Quizzlet: https://quizlet.com/user/rottenbanana_/folders/ethics?i=6f4vkg&x=1xqt


# **Ethics – Lecture 1: Introduction & Foundations**

### 💡 **What is Philosophy?**
- Explores problems **not solvable** by empirical research alone
- Sciences often **originated** from philosophy
- Branches:
  - **Epistemology**: What is knowledge?
  - **Logic**: Valid reasoning (truth-preserving structures)
  - **Metaphysics**: Time, causation, nature of reality
  - **Ethics**: What makes actions right or wrong?

---

### 🔍 **Three Branches of Ethics**
1. **Meta-ethics**: What do moral terms mean? (e.g., "wrong")
2. **Normative ethics**: What moral rules should we follow?
3. **Applied ethics**: What should be done in specific cases?

---

### 🧠 **Philosophy ≠ Personal Opinion**
- It’s about well-reasoned, **rational arguments**, not feelings
- Essay grading based on **strength of argument + theory knowledge**
- Avoid relying solely on intuition/common sense

---

### ⚖️ **Moral Reasoning Essentials**
1. **“No ought without can”** – You can’t be morally obligated to do the impossible
2. **“No ought from is”** – Moral claims can't be derived from facts alone
3. **Explanation ≠ Justification** – Explaining motive ≠ morally justifying action

---

### 💬 **Value vs Empirical vs Conceptual Claims**
- **Empirical**: Testable with senses (e.g., “Lies hurt people”)
- **Value**: Normative judgment (e.g., “Lying is wrong”)
- **Conceptual**: True by meaning (e.g., “Triangles have 3 sides”)

---

### 🧠 **Valid & Sound Arguments**
- **Valid**: If premises are true → conclusion must be true
- **Sound**: Valid **+** all premises are **true**
- Example of **valid but unsound**:
  - P1: All unicorns are blue.
  - P2: Lucy is a unicorn.
  - C: Lucy is blue. ✅ Valid ❌ Not sound (P1 is false)

---

### 🧭 **Value Arguments**
- Require **at least one** value premise (e.g., “hurting is wrong”)
- You cannot conclude "X is wrong" from facts **alone**

---

### 💍 **Gyges' Ring Thought Experiment**
- Glaucon: People are only moral **because they have to be**
- Question: Is there such a thing as **genuine moral action**?

---

### 🧍‍♂️ **Psychological Egoism**
- View: All human actions are **self-interested**
- **Hobbes**: Even pity is self-interest
- **Normative egoism**: We **should** always act in self-interest

---

### ❤️ **Criticisms of Psychological Egoism**
- **Hume**: We have **natural benevolence**
  - Moral failures aren’t always selfishness – could be misplaced benevolence
- **Williams**: All actions are based on desire, but **not all desires are selfish**
- **Distinction**:
  - Self-interest ≠ selfishness
  - Selfishness = **excessive** concern with self

---

### ✅ **Conclusion: Is There Genuine Moral Action?**
- **If Hume is right**: Yes, at least sometimes we act for others' sake
- **If Williams is right**: Acting on desires is fine if they’re not all self-directed
- Taking care of oneself isn’t inherently selfish

---
---

# **Ethics – Lecture 2: Conventional Morality & Challenges to It**

### ⚖️ **Conflicts of Interest: Common Ethical Dilemmas**
Examples include:
- Offering side services to company clients
- Accepting favors for inside info
- Overlooking misconduct due to friendship
- Using company knowledge for personal gain
- Consulting for competitors or arranging future jobs with current clients

These highlight tensions between **loyalty** to the company vs. **personal benefit**.

---

### ❓ **Is Conventional Morality Enough?**
- Asking “what’s usually done” ≠ knowing what’s morally right
- **Conventional morality** = Social norms, often uncritically followed
- True ethics requires reflection beyond social norms

---

### 🧠 **Philosophy & Definitions**
- Philosophical terms often **lack fixed definitions**
- Dictionaries reflect **common usage**, not **philosophical depth**
- Don’t rely on Google definitions (e.g., “objectivism” ≠ Ayn Rand in this course)

---

### 🧍 **Revisions: Egoism & Self-interest**
- **Psychological Egoism**: We *always* act in self-interest (descriptive)
- **Normative Egoism**: We *should* act in self-interest (prescriptive)
- **Self-interest** is natural (e.g. eating); **selfishness** is excessive concern for self
- **Williams**: Desiring ≠ being selfish — it depends *what* we desire
- **Aristotle**: Moral action can be enjoyed; that doesn’t make it selfish

---

### 🔍 **Revisions: Validity vs Soundness**
- **Valid** = conclusion logically follows from premises
- **Sound** = valid + all premises are true
- A valid argument can have false premises or a false conclusion — **only sound arguments guarantee true conclusions**

---

### 🧒 **Kohlberg’s Stages of Moral Development**
Inspired by Piaget; suggests **moral reasoning matures with cognitive ability**:

#### **Level 1: Preconventional Morality**
1. **Obedience & Punishment**: Authority = right; avoid punishment
2. **Instrumental Exchange**: Self-interest and fair deals ("what’s in it for me?")

#### **Level 2: Conventional Morality**
3. **Good Boy/Nice Girl**: Seek praise from peers/family
4. **Law & Order**: Law = order = morality; societal focus (without questioning authority)

#### **Level 2.5: The Cynic**
- Recognizes morality is constructed but lacks moral foundations
- Can lead to relativism or "do your own thing" ethics
- Risk: rebellion without replacement

#### **Level 3: Postconventional Morality**
5. **Social Contract & Individual Rights**: Democratic processes, human rights
6. **Universal Moral Principles**: Civil disobedience justified when laws are unjust (e.g. MLK)

---

### 🐖 **Peter Singer – Challenging Convention**
- Utilitarian; advocates **equal consideration of interests**
- Rejects **speciesism**: unjust moral preference for humans over other animals
- Analogous to racism or sexism – humans ≠ intrinsically superior
- Rights ≠ identical treatment: e.g. pigs don’t need voting rights, but *do* have interests

---

### 🧠 **What Is Equality?**
- **Not a statement of fact**, but a **moral ideal**
- Based on **ability to suffer**, not merit/intelligence
- “The question is not, Can they reason? but, Can they suffer?” – **Bentham**
- Singer opposes **Frankena’s human-only dignity**: some animals > some humans in cognitive abilities

---

### 💭 **Discussion Prompts**
- Are we morally speciesist? Is it wrong?
- What ethical conventions exist in computing today?
- Do traditions (e.g. loyalty clauses in contracts) define what’s right?
- Singer challenges us: if rights aren’t based on species, how should we define them?

---
---

# **Ethics – Lecture 3: Relativism vs Objectivism**

### ⚔️ **Central Debate**
- **Moral Relativism**: Right/wrong depends on **culture**, group, or individual perspective.
- **Moral Objectivism**: At least **some moral truths** are universally valid, regardless of culture.

---

### 🌍 **Examples from Class**
- **Russia/Ukraine cyberwar**:
  - Relativist: Both Russia and Ukraine are right **from their own perspectives**.
  - Objectivist: Cyberattacks are wrong, regardless of the actor.
- **Dark ATM UI ("Dark Patterns")**:
  - Relativist: Ethical/unethical depends on user vs. bank perspective.
  - Objectivist: Tricking users is unethical regardless of design norms.

---

### 🧠 **James Rachels’ Critique of Cultural Relativism**
**Key Mistake**: Moving from an **empirical claim (is)** to a **normative claim (ought)**  
✔️ 1. **True**: Cultures have different moral codes  
❌ 2–6. **False**: Therefore no objective morality

**If relativism were true**:
1. No cultural criticism possible (e.g., FGM, slavery would be untouchable)
2. No moral progress possible
3. Right = whatever your society says

---

### 💬 **Common Arguments for Relativism**
- "We should never judge"
- "All cultures are equally valid"
- "You can't understand other people’s motives"
- "Everyone is hypocritical anyway"

**Response**:
- Judging ≠ interfering
- Judging ≠ rejecting entire cultures
- Tolerance doesn’t mean accepting everything

---

### 📜 **Biblical Misinterpretation & Fallacy**
- “Do not judge” (Matthew 7:1–5) used to defend non-judgement
- **Fallacy**: *Appeal to Hypocrisy* – “You lied once, so you can't say lying is wrong”
  - Rebuttal: The **truth of a claim** doesn't depend on the **speaker's character**
  - Example: Even a thief can say “stealing is wrong” — and be right.

---

### ⚖️ **Key Distinctions**
| Term                        | Meaning                                                                 |
|----------------------------|-------------------------------------------------------------------------|
| **Descriptive Relativism** | Cultures differ in moral views (empirical fact)                         |
| **Normative Relativism**   | There is no universal morality – all values are culture-bound           |
| **Objectivism**            | Some values apply to all people, in all cultures                        |
| **Absolutism**             | There are **rigid, exceptionless rules** (e.g., "never lie")             |
| **Non-Absolutist Objectivism** | Morality is objective but **context-sensitive** (e.g., utilitarianism)     |
| **Circumstantialism**      | Context matters, but **truth is still objective** (not the same as relativism) |

---

### 🧪 **Moral Objectivism ≠ Being Psychologically Objective**
- **Objectivist** = Philosophical position (relativism is false)
- **Objective person** = Unbiased thinker (many objectivists are biased!)
- E.g. Hitler and Gandhi = both objectivists, vastly different morals

---

### 📚 **Rachels: Morality Grounded in Objective Social Needs**
- All societies need to protect infants → objective reason = survival
- Common values like honesty, fairness, loyalty are necessary for functioning society

---

### 🔄 **Rachels: Many Disagreements Are Surface-Level**
- E.g. Hindus don’t eat cows → due to belief in reincarnation, not a deeper moral difference
- Moral disagreement often comes from **empirical**, not ethical, disagreement

---

### 🐷 **Singer & Equality**
- Moral equality ≠ factual sameness
- "Can they suffer?" – Basis for rights, not intelligence or species (Bentham)
- **Speciesism** = Unjustified moral bias toward humans (like racism)

---

### ❓ **Scenarios: Relativist vs Objectivist vs Absolutist**
| Scenario                                                                 | Type            |
|--------------------------------------------------------------------------|------------------|
| "Every cyberattack is wrong, no matter what"                             | **Objectivist + Absolutist** |
| "If I were Russian, I’d think differently"                               | **Relativist**   |
| "Stealing from rich companies is always OK"                              | **Objectivist (but wrong)** |
| "I follow my company's policy on what's ethical"                         | **Relativist**   |

---

### 💬 **Can Objectivists Be Tolerant?**
- Yes!
- Tolerance makes sense only **if some values are non-negotiable**
- Even self-proclaimed relativists often **aren’t consistent** (they’ll judge Nazis, for example)

---

### ✅ **Key Takeaways**
- We can acknowledge **cultural differences** without giving up on the idea of **universal ethics**
- Moral objectivism is the **rejection of relativism** – it doesn't mean being rigid or closed-minded
- Judgement is **necessary for moral reasoning**
- Objectivism allows for tolerance – **Relativism confuses tolerance with moral inaction**

---
---

# **Ethics – Lecture 4 Summary: Utilitarianism I**

### 🧭 **Ethical Judgement and Tolerance (Review)**
- Judge actions **fairly** – don’t blindly follow your company’s or culture’s moral values.
- **Avoid two extremes**:
  - **Excessive tolerance**: refusing to morally evaluate harmful behavior
  - **Hypermoralism**: over-policing or moral panic

---

## ⚖️ **Introduction to Normative Ethics**
Three main theories:
| Theory            | Focus                         | Key Figures             |
|------------------|-------------------------------|-------------------------|
| **Virtue Ethics** | Moral character, motivation   | Aristotle, Hume         |
| **Kantian Ethics**| Duty and rational intention   | Kant                    |
| **Utilitarianism**| Outcome: pleasure vs. pain    | Bentham, Mill           |

---

## 💻 **Applied Focus: Hacking**
- **White Hat** = ethical, legal, with consent
- **Black Hat** = illegal, harmful intent
- **Grey Hat** = unauthorized but not malicious; may offer help

**Utilitarian view**: What matters is **consequences** – even black or grey hat hacking could be **morally right** if it increases total happiness or prevents greater harm.

---

## 🧠 **Jeremy Bentham: Classical Act Utilitarianism**
### Core Tenets:
1. **Psychological Hedonism**: We are governed by **pleasure and pain**
2. **Normative Hedonism**: Pleasure is the **only intrinsic good**, pain the only bad
3. **Consequentialism**: Morality of an action = outcome (utility)
4. **Felicific (Hedonic) Calculus**:
   - Evaluate **intensity, duration, certainty, proximity, fecundity, purity, extent**
5. **Equal Consideration of Interests (ECI)**:
   - Every individual’s pleasure/pain counts **equally**
6. **No action is inherently wrong** – only wrong if it fails to maximize utility

### Famous Quote:
> "Nature has placed mankind under the governance of two sovereign masters, pain and pleasure." – *Bentham*

---

## 📈 **Clarifications on Utilitarian Principles**
- **“Greatest happiness for the greatest number”** ≠ fairness or equal treatment
- Only **total net happiness** matters – even if only **one person benefits**
- Not about **distribution**, but **aggregation** of pleasure/pain

---

## 🧑‍🏫 **John Stuart Mill’s Refinement**
| Bentham                         | Mill                              |
|--------------------------------|-----------------------------------|
| Quantitative utility only      | **Qualitative** differences matter |
| Pleasure = any sensation       | Some pleasures are **higher**     |
| Psychological egoism           | Rejected; **moral motivations** exist |
| Felicific calculus emphasized  | **Competent judges** assess pleasure quality |
| External sanctions (laws)      | Internal sanctions (conscience, guilt) |

> “Better to be a human dissatisfied than a pig satisfied.” – *Mill*

---

### 🔍 **Mill’s Greatest Happiness Principle**
> “Actions are right in proportion as they tend to promote happiness, wrong as they tend to produce the reverse.” – *Mill*

- Utility = **Pleasure – Pain**
- Right action = **maximizes utility** out of all available options

---

### 🧠 **Mill’s Proof of Utility**
- If people **desire** happiness, it must be **desirable**
- Like “visibility” is proven by seeing, “desirability” is shown by being desired

---

## 🧪 **Utilitarianism in Practice**
| Scenario                                                                                   | Utilitarian View           |
|--------------------------------------------------------------------------------------------|----------------------------|
| **Jim’s Dilemma** (kill 1 to save 20)                                                      | Must kill the 1            |
| **Trolley Problem** (flip switch to save 5, kill 1)                                        | Flip the switch            |
| **Fat Man Variant** (push one to save 5)                                                   | Push him                   |
| **Friend Andy’s server hack covered up by lie**                                            | Lying is morally required if it leads to better outcome |
| **Mr. Strangelove hacker nearly starts WWIII, then saves the world**                      | Action turns out moral (good outcome) |

---

### ⚠️ **Challenges to Utilitarianism**
- Can allow actions that seem intuitively wrong (e.g. sacrificing one for many)
- **Ends justify the means**, even if means are disturbing
- Doesn’t always capture **moral motives, justice, rights**

---

## ✅ **Summary: Utilitarianism**
| Feature                     | Bentham                          | Mill                               |
|----------------------------|----------------------------------|------------------------------------|
| Psychological View         | Hedonist & Egoist                | Hedonist, not Egoist               |
| Theory Type                | Act Utilitarianism               | Refined Act Utilitarianism         |
| Measurement                | Quantity of pleasure             | **Quality + Quantity**             |
| Focus                      | Hedonic Calculus                 | Competent Judges                   |
| Action Judgment            | Based on total pleasure/pain     | Based on best happiness for all    |

---
---

# **Ethics – Lecture 5: Objections to Utilitarianism & Dark Patterns**

### 🌐 **Dark Patterns in UX Design**
- **Definition**: UX designs that manipulate users into actions not in their best interest.
- **Legal Status**:
  - **Canada**: Not fully regulated yet.
    - *PIPEDA*: Consent guidelines (Privacy Commissioner)
    - *CASL*: Bans misleading e-messages
    - *Bill C-27 (proposed)*: Explicitly bans deceptive consent practices
- **Ethical Note**: Legality ≠ Morality

### 🧠 **Why Utilitarianism Applies Here**
- **Rejects absolutism**, so it can evaluate manipulation based on **outcomes**.
- **Avuncular Ethics**: Manipulating someone for their benefit (e.g. auto-enroll pensions).
- Contrasted with **Kantian Ethics** which **always rejects manipulation**, regardless of outcomes.

---

## 📉 **Common Misunderstandings of Act Utilitarianism**

| **Claim** | **Clarification** |
|----------|------------------|
| “Maximize happiness for the majority” | ❌ Wrong. Maximize **total utility**, not distribution or majority. |
| “The action is moral because it causes happiness” | ❌ No. It must **maximize** utility out of all available options. |
| “Respecting contracts always maximizes utility” | ❌ Evaluates **actions**, not general rules. |
| “Benefits outweigh the costs” | ❌ May apply to many options—utilitarianism chooses the **best** one. |

---

## 🧱 **Mill’s Three Classical Objections (with Responses)**

1. **Doctrine of Swine**  
   ❌ Objection: Pleasure-only focus is base, fit for animals.  
   ✅ Mill: **Higher vs. lower pleasures** (quality matters, judged by “competent judges”).

2. **Too High for Humanity**  
   ❌ Objection: Unrealistic to always act for general welfare.  
   ✅ Mill: Ethics tells us which actions are right, not which **motives** we must always have.

3. **Lack of Time**  
   ❌ Objection: No time to calculate utility before acting.  
   ✅ Mill: We rely on **learned experience**; no need to calculate each time.

---

## ❌ **Key Objections to Utilitarianism (Beyond Mill)**

### 1. **Psychological & Normative Hedonism**
- We **don’t always act** from pleasure-seeking (e.g. truth-seeking despite pain).
- **Nozick’s Experience Machine**:
  - We value **reality, character**, and **authenticity** beyond just pleasure.

### 2. **Desire-Fulfillment Theory (Mill’s Proof)**
- Desire ≠ moral goodness.
- Addictions, self-destructive desires aren’t morally good just because they’re desired.

### 3. **Aggregating Utility**
- May justify morally troubling actions if the overall result is beneficial.
- Example: Sharing someone’s private data stops a crime → Was it moral?

### 4. **Negative Responsibility**
- Objection: Treats **omission** as morally equal to **commission**.
- *Williams’ “Jim and Pedro”* case: Refusing to kill one may be blamed for 19 deaths.
- Challenges the concept of **moral integrity**.

### 5. **Trivial Actions**
- Utilitarianism implies even leisure or personal time may be wrong if not utility-maximizing.

### 6. **Promises**
- Promises not **intrinsically moral** to keep—only if breaking them reduces utility.
- *Example*: Promise to bury grandfather, but survival may require breaking it.

### 7. **Punishment & Justice**
- Justified **only if** it maximizes utility:
  - Could justify punishing innocent if it deters crime or pleases many (vengeance).
  - Ignores **fairness**, **rights**, **innocence** as intrinsic moral values.

### 8. **Justice & Fairness**
- Fair pay or treatment is moral **only if** it leads to better outcomes.
- **Slavery** may be deemed moral if it leads to flourishing (deeply problematic).

### 9. **Supererogation**
- **Charity is not optional**—it becomes a **moral duty**.
- *Singer*: Affluent people must help distant strangers if they can do so without major sacrifice.
- **Implication**: Utilitarianism **eliminates** the distinction between duty and generosity.

### 10. **Impartiality**
- All people matter **equally**, regardless of relationship.
- May imply: Must save two strangers over your own child.
- Objections:
  - “No ought without can” – humans may not be psychologically capable of such impartiality.
  - There are **special duties** (to family, friends, etc.)

---

## 🎯 **Core Objections Recap (List)**

- "Doctrine of Swine"
- "Too high for humanity"
- "Lack of time"
- Hedonism (both psychological & normative) is flawed
- Mill's proof doesn’t establish moral value
- Aggregating utility leads to injustice
- Blames omissions too harshly
- Doesn’t handle trivial actions well
- Doesn’t value promises intrinsically
- Treats justice & rights as secondary
- Makes all charity into moral duty
- Unrealistic impartiality

---

## 🤔 Final Reflection Questions
1. Can you respond to each objection with a solid defense?
2. Which objection do you find most damaging?
3. Are you still a utilitarian? Why or why not?
4. Can we ever abandon social utility completely?

---
---


# **Lecture 6: Kant I – Deontology and Moral Duty**

## 📌 **Overview**
- Focus: Kant’s rejection of utilitarianism and development of a **deontological** ethics grounded in **reason** and **duty**.
- Emphasis on **motive**, **autonomy**, and the **categorical imperative (CI)**.
- Application to **intellectual property** and professional conduct (e.g., copyright, patents, trade secrets).

---

## 🧠 **Core Concepts**

### **1. Kantian Ethics is Deontological**
- **Deontology** = Ethics based on **duty**, not consequences.
- Actions are **right/wrong in themselves**, not because of their outcomes.
- Morality is about **doing the right thing for the right reason** (i.e., from duty).

### **2. Motives Matter**
- Only actions done **from duty** (not from self-interest, emotion, or inclination) have **moral worth**.
  - Ex: Helping someone because it’s your **duty** = morally worthy.
  - Helping someone out of **pity or love** = not morally worthy (even if right).
- The right action + the right motive = action with **moral worth**.

---

## 🔄 **Kant vs. Utilitarianism**
| Kant | Utilitarianism |
|------|----------------|
| Action’s **motive** matters most | Action’s **consequence** matters most |
| Reason is moral foundation | Pleasure/happiness is moral foundation |
| **Absolutist** – some actions are always wrong (e.g. lying) | **Consequentialist** – even lying may be moral if it maximizes utility |

---

## 🔥 **Kant’s Key Contrasts**
| Concept | Kant's View |
|---------|-------------|
| **Motives** | Duty vs Inclination |
| **Imperatives** | Categorical vs Hypothetical |
| **Freedom** | Autonomous vs Heteronomous will (covered in Kant II) |

---

## 🧾 **Kant’s Imperatives**

### 🔹 **Hypothetical Imperatives** (means-end reasoning)
- Conditional: “If you want X, do Y.”
- Example: “If you want to avoid prison, don’t steal.”

### 🔹 **Categorical Imperative (CI)** – Supreme moral law
- **Unconditional**: Applies to everyone, regardless of desires.
- Defines **ends**, not just means.

---

## 🔁 **Three Formulations of the CI**

### **1. Formula of Universal Law**  
“Act only on that maxim whereby you can at the same time will that it should become a universal law.”

### **2. Formula of Humanity**  
“Act so that you treat humanity, whether in your own person or that of another, always as an end and never merely as a means.”

### **3. Formula of Autonomy** *(covered in Lecture 7)*  
“Act so that through your maxims you could be a legislator of universal laws.”

---

## 🧪 **Four-Step CI Procedure (from SEP)**

1. **Formulate the maxim** (your reason for acting).
2. **Universalize it** (what if everyone did it?).
3. **Test 1 – Contradiction in Conception**  
   - Is the world where this maxim is universal even **conceivable**?  
   - If **no**, it's a **perfect duty** to never do it.
4. **Test 2 – Contradiction in Will**  
   - Can you **rationally will** this universal law?  
   - If **no**, it's an **imperfect duty** to avoid **never** doing it.

---

## 📊 **Types of Duties (Kant)**

| Duty Type | Towards Self | Towards Others |
|-----------|--------------|----------------|
| **Perfect Duties** (always forbidden) | No suicide | No lying, theft |
| **Imperfect Duties** (sometimes required) | Self-improvement | Helping others |

- **Permissible Actions** = Pass both tests but are not required (e.g. going for a walk).
- **Supererogation** = Doing more than duty requires. Kant allows for this via **imperfect duties**, unlike utilitarianism.

---

## 🧩 **Example Applications**

### **1. Lying to escape trouble**
- **Maxim**: “Lie when in trouble”
- **Universal Law**: Everyone lies when in trouble → contradiction in conception.
- **Result**: Violates perfect duty → always wrong.

### **2. Refusing to help others**
- **Maxim**: “Never help others”
- **Universal Law**: No one helps anyone → conceivable, but not rational to will.
- **Result**: Violates imperfect duty → morally wrong if you never help.

---

## 🔐 **Copyright, Patents, and Trade Secrets**
- **Stealing IP** = Treating creators as **mere means**
- Kant: You must not violate intellectual property, even if doing so benefits you or avoids consequences.
- **Example CI test**:
  - **Maxim**: “Steal IP when under pressure”
  - Fails **universalization** (undermines concept of ownership).
  - Therefore, it’s a **perfect duty** not to do it.

---

## ✅ **Key Takeaways**
- Kantian ethics emphasizes **reason, autonomy, and duty**.
- The **categorical imperative** is used to determine **moral duties**.
- **Perfect duties** = absolute moral prohibitions (e.g., no lying).
- **Imperfect duties** = actions we must do **sometimes** (e.g., help others).
- Treating others as **ends in themselves**, not as **mere means**, is essential.
- Motivation matters: doing the right thing **for the right reason** is what makes an action morally worthy.

---
---

# **Lecture 7: Kant II – Freedom and Ethics**

### **1. Kant’s View on Freedom**
- **Freedom ≠ absence of rules.** True freedom is autonomy, which requires acting according to rational moral laws, not inclinations.
- **Heteronomy**: Acting based on inclinations or external factors (e.g. mood, self-interest).
- **Autonomy**: Acting based on reason you legislate for yourself—rational, moral law.

> **Autonomy Formula (3rd Formulation of CI)**:  
> “Act so that through your maxims you could be a legislator of universal laws.”

### **2. OSS and Property Rights**
- **Open Source ≠ Public Domain**: Still governed by licenses (rules), hence property rights are relevant.
- **Kantian Implication**: Respecting OSS licenses = respecting collective promises; breaking them is using others as mere means.

---

### **3. Kant on Suicide**
- **Kant’s Position**: Suicide is always wrong; it violates perfect duties to self and uses oneself as a mere means to escape suffering.
- **Paul Edwards' Critique**:
  - Kant confuses “I must do my duty while alive” with “I must stay alive no matter what.”
  - Ignores suffering, mental health, and compassionate motives.

---

### **4. Moral Conflict: Conflict of Duties**
- **Problem**: Kant provides no mechanism to resolve moral dilemmas involving two conflicting duties (e.g., lie or break promise).
- **Example**: Must tell truth to a murderer at the door, even if it causes death—absolutist stance.

---

### **5. Kant’s Rejection of Consequentialism**
- **Consequences ≠ Morality**: Rightness depends on **motive**, not **outcome**.
- **Kant allows misleading truths** (if not a lie), e.g., “This tie is unique!”
- **Utilitarianism** would say: sometimes, lying or violating rights is justified if it brings about the greater good.
- **Kant** says: Never.

---

### **6. Are Inclinations Always Accidental?**
- **Kant**: Yes – acting from inclination (even altruistic ones) lacks moral worth.
- **Critique**: Modern psychology and virtue ethics (Aristotle) show we can **train inclinations**, making them **part of virtuous character**.

---

### **7. Acting from Duty: Is It Enough?**
- **Charlie Example**: Charlie wants to kill his parents daily, but refrains purely out of duty.
  - **Kant**: Moral.
  - **Critics**: This seems psychopathic. Motive quality matters beyond just duty.

---

### **8. Kant vs Hume on Reason**
- **Kant**: Reason alone should define our ends; morality is rational.
- **Hume**: Motivation = reason + desire; emotions are essential.
- **Critique**: Kant may underestimate role of emotion and overestimate the purity of rational choice.

---

### **9. Equal Capacity for Autonomy?**
- **Kant**: All rational beings equally capable of autonomy.
- **Critique**: A child soldier or uneducated person might not have the same opportunity or capacity to reason morally.
- **Virtue Ethics / Mill**: Moral education, social context, emotional training matter.

---

### **10. Freedom vs Determinism**
- **Physical World**: Governed by causal determinism (e.g. gravity).
- **Moral World (Intelligible Realm)**: Humans are “uncaused causes,” morally free to choose rationally.
- **Challenge**: If brain is physical, how can freedom exist?

---

### **11. Kantian Ethics: Summary of Key Problems**
| Problem | Description |
|--------|-------------|
| **Suicide** | Absolutist ban ignores suffering, autonomy. |
| **Conflict of Duties** | No way to resolve moral dilemmas. |
| **No Role for Consequences** | Leads to implausible moral outcomes. |
| **All Inclinations Dismissed** | Neglects trained/emotionally healthy dispositions. |
| **Acting from Duty Suffices** | Allows cold, psychopathic moral agents. |
| **Freedom Assumed Equally** | Ignores disparities in moral education or capacity. |
| **Rationality as Only Motivation** | Contradicted by Hume & modern psychology. |



---
---

# **Ethics Lecture 8: Virtue Ethics I**

### 🧠 Key Themes
- Virtue ethics as an alternative to utilitarianism and Kantian ethics.
- Focus on character, emotional dispositions, and moral education.
- Objectivism, motivation, and the role of emotions in moral action.

---

### 🔍 **Core Figures**
- **Aristotle (384–322 BC)**: Virtue as the "golden mean" between extremes. Good life = flourishing (eudaimonia).
- **David Hume (1711–1776)**: Emphasized emotions and utility, introduced “true interest” and HTM (Hume’s Theory of Motivation).

---

### 🧭 **Virtue Ethics vs Other Theories**
| Feature              | Virtue Ethics           | Utilitarianism             | Kantian Ethics                |
|----------------------|--------------------------|-----------------------------|-------------------------------|
| Moral Focus          | Character traits         | Consequences (utility)      | Motive + duty                 |
| Role of Emotion      | Central (virtues = emotional dispositions) | Minimal                      | Distrusted                    |
| Rationality          | Practical reason helps fine-tune emotion | Means to utility             | Reason defines duty           |
| Motivation           | Emotions & rational habits | Desire for happiness       | Duty, acting from reason      |

---

### 🔁 **Objectivism in Virtue Ethics**
- Moral facts = facts about **human nature**.
- **True interest** ≠ self-interest or mere desires.
- Character traits (virtues/vices) are judged by how well they help humans flourish (e.g. loyalty, honesty, justice).

---

### 🔧 **Hume’s Theory of Motivation (HTM)**
- Motivation = **belief + desire** (not reason alone).
- **Reason is a slave of the passions**: reason helps figure out how to get what you want, but cannot determine what you want.

**Examples**:
- “I want to pass the test” + “Studying helps” → motivation to study.
- Reason alone does not motivate; must be paired with a passion.

---

### 🌟 **What Is a Virtue?**
- **Aristotle**: Virtue = golden mean (e.g. courage = between recklessness and cowardice).
- **Hume**: Virtue = emotional disposition useful to self and others.
  - E.g., honesty = trust, loyalty = social bonds.

---

### 🧩 **Why Be Virtuous?**
1. **Intrinsic Value**:
   - Virtuous actions are valuable in themselves.
   - Better to be brave than cowardly even if no reward follows.

2. **Extrinsic Value**:
   - Virtue = social capital (love, admiration).
   - Even the selfish can benefit from being seen as virtuous.

3. **True Interest**:
   - Flourishing = eudaimonia (not pleasure).
   - Living virtuously = living well (Aristotle).

---

### 🧠 **Virtue, Conflict, and Character Types**

| Type              | Description                                                                 |
|------------------|-----------------------------------------------------------------------------|
| **Perfectly Virtuous** | Desires align with moral good, no internal conflict. Enjoys doing the right thing. |
| **Continent (Enkrateia)** | Knows the good, tempted by vice, but chooses virtue. Strength of will.            |
| **Incontinent (Akrasia)** | Knows the good, fails to act on it. Weak will, internal conflict.               |
| **Impetuous**     | Acts without reflection, no internal conflict or awareness.                |

---

### ⚔️ **Key Terms**
- **Eudaimonia**: A flourishing life, not merely happiness.
- **Akrasia**: Lack of mastery (weakness of the will).
- **Enkrateia**: Self-control (continent person).
- **Virtue**: Character traits conducive to one’s flourishing and true interests.

---

### 🔍 **Example Discussions**
- **Prison scenario**: Do you keep a promise even at great personal cost?
- **Remote work**: Do we work hard out of fear (external policing) or character (virtue)?
- **Gyges’ Ring** revisited: Will you act morally without oversight?

---

### 🧠 Final Takeaways
- Virtue ethics emphasizes long-term character formation over moment-to-moment rule following or cost-benefit analysis.
- It is not about being “saintly” but about becoming the kind of person whose desires naturally align with moral good.
- Emotions and reason must be trained together to develop the virtues that constitute a flourishing life.

---
---

# Ethics Lecture 9: Virtue Ethics II

### 🌟 Theme: Learning to be Moral | Role of Reason | Character in Practice

---

### 💻 Modern Application: Remote Work & Character
- Bullying in remote work can stem from poor character:
  - Zoom shame, email coldness, misinterpretation due to lack of non-verbal cues.
  - Example: John Suler's *Online Disinhibition Effect*:
    - Anonymity, invisibility, delayed interaction, imagined identities, detachment from reality, diminished authority.

---

### 🧠 Reason vs. Emotion Across Theories

| Theory        | Conception of Reason | Role of Emotion |
|---------------|----------------------|------------------|
| **Mill**      | Means-end + internal sanctions | Emotions not relevant for judging moral worth |
| **Kant**      | Reason = source of morality (CI); reason vs. inclination | Emotions are accidental, unreliable |
| **Hume**      | Reason is instrumental only (“slave to passions”) | Emotions define ends; virtues are emotional dispositions |
| **Aristotle** | Practical reason (phronesis) + reason about ends | Emotion and reason work together; virtues are trainable traits |

---

### 🧭 Aristotle: Practical Reason & Moral Education
- **Virtues**: Right actions in the right way, for the right reasons.
- **Moral Education**: Learn “that” X is wrong → Learn “why” it is wrong (via *phronesis*)
- **Character** is cultivated, not innate → we are responsible for who we become.
- “No man knowingly does wrong” (Socrates): A person who truly knows virtue will desire it.
  - E.g. someone who hates camping may just be untrained to appreciate it.

---

### 🧰 Hume: Natural vs Artificial Virtues
- **Natural virtues**: e.g. Benevolence, Loyalty — arise naturally but are partial (e.g. only toward family/friends).
- **Artificial virtues**: e.g. Justice — learned, rooted in social utility/common good.
- **Use of reason**: Filter our partiality, adopt the “general point of view” (to maintain consistent moral standards).

---

### ⚖️ Evaluating Actions with VE
- **Rosalind Hursthouse’s Framework**:
  1. Action is **right** if it’s what a *virtuous agent* would characteristically do.
  2. A virtuous agent acts **according to virtues** that promote **eudaimonia** (flourishing life).
  3. So, we reason: “What would a virtuous person do here?”
- **Guidelines**, not strict codes:
  - Is my trait in the **golden mean**? (Aristotle)
  - Is it socially useful? (Hume)
  - Am I being consistent?

---

### ❓ Objections & Responses

| Objection | VE Response |
|----------|-------------|
| “VE lacks a code” | Moral knowledge = a skill; can’t be captured by strict rules |
| “VE is relativist” | No – it’s **context-sensitive**, not **relativist**; virtue is discovered, not invented |

---

### 💡 Application Levels in VE

| Condition       | Deliberation? | Right Action? | Moral Worth? |
|----------------|---------------|---------------|--------------|
| **Fully virtuous** | Intuitive | ✅ | ✅ |
| **Continent (self-controlled)** | Yes | ✅ | ✅ |
| **Weak (incontinent)** | Yes | ❌ | ❌ |
| **Impetuous** | No | ❌ | ❌ |
| **Amoral/ignorant** | No | ❌ | ❌ |

---

### 🔁 VE on Costly Moral Actions
- Rejects self vs. others divide.
- Virtuous action ≠ always self-sacrifice:
  - Can yield long-term benefits (social bonds, self-respect)
  - Offers intrinsic satisfaction (virtue is pleasurable when mastered)

---

### 🧠 Summary Thought
- VE emphasizes *becoming* moral through habits and understanding, not just *doing* moral acts.
- It offers tools to *grow into* moral agency rather than *follow* rigid rules.

---
---



# 📘 Ethics Lecture 10 – Rawls & Nozick: Theories of Justice

### 🧭 Political Philosophy: Ethics Applied to Social Structures
- Examines the moral legitimacy of power, justice, liberty, and wealth distribution.
- Applied in assessing fairness in **government**, **institutions**, and **business**.

---

## ⚖️ Rawls – *Justice as Fairness* (Liberal Egalitarianism)

### 🧠 Key Concepts:
- **Original Position**: Hypothetical scenario of equality.
- **Veil of Ignorance**: Thought experiment – we decide fair principles without knowing our future social position (race, class, sex, etc.).

### 🌟 Guiding Ideas:
1. **Negative Thesis**: Birth circumstances (race, family, abilities) are morally arbitrary and should not influence one’s prospects.
2. **Positive Thesis**: All social goods should be equally distributed unless unequal distribution benefits everyone.

---

### 📜 Rawls’ Two Principles of Justice:
1. **Equal Liberty Principle**: Everyone has an equal right to the most extensive liberty compatible with similar liberty for others.
2. **Difference Principle**: Inequalities are just only if:
   - They benefit the least advantaged.
   - Positions attached to them are open to all (formal equality of opportunity).

### 🚫 Critique of Meritocracy:
- Even *perfect* meritocracy is flawed—natural talents are not deserved.
- Inequalities are just **only if** they improve conditions for the least well off.

---

## 🧍 Nozick – *Entitlement Theory of Justice* (Libertarianism)

### 🧩 Core Beliefs:
- Individuals have **natural rights** (Locke): life, liberty, property.
- People own themselves = **Self-ownership**.
- The **minimal state** (defense, police, courts) is the **only justifiable state**.
- Redistribution = violation of liberty = **coercion**/**theft**.

### 🛠️ Just Acquisition & Transfer:
1. **Justice in Acquisition**: No theft, fraud.
2. **Justice in Transfer**: Voluntary exchange.
3. **Rectification**: Fixing past injustices.

**Key Maxim**:  
> “Whatever arises from a just situation by just steps is itself just.” — Nozick

---

### 🧪 Example: Wilt Chamberlain Case
- If people **voluntarily** pay to see Wilt, he deserves the money.
- Enforcing redistribution would violate liberty and property rights.

### ⚠️ Nozick’s Claims:
- **Taxation = slavery**: it compels your labor for others.
- Redistribution = forced charity.
- The **natural lottery** is not unjust—just a fact of life.

---

## 🔄 Comparing Rawls & Nozick

| Feature                   | Rawls                                     | Nozick                                 |
|--------------------------|-------------------------------------------|----------------------------------------|
| Justice focus            | **Fairness** & reciprocal benefit         | **Liberty** & property rights          |
| Role of government       | Correct inequalities                      | Protect rights only                    |
| View on redistribution  | Yes, if it benefits least advantaged       | No, violates liberty                   |
| Basis of rights          | Kantian autonomy, fairness                | Self-ownership, Locke’s natural rights |
| View of meritocracy      | Arbitrary, not morally relevant           | Acceptable if based on just transfers  |
| On taxation              | Required for justice                      | Equivalent to slavery                  |

---

## 💡 Applications to Workplace Ethics:
- **Contracts must be both consensual and mutually beneficial**.
- Contracts (e.g., unpaid overtime, non-disclosure agreements) lose moral force if **reciprocity** is missing.
- **Social contracts** imply obligations even without explicit consent.

---

## 🧠 Discussion Questions:
1. Would you accept unpaid overtime to help fund coworkers’ mental health care?  
   - **Rawls**: Yes, if it benefits the least advantaged.
   - **Nozick**: No, it’s coercion.

2. Can taxation be justified to support those in need?
   - Rawls: Yes.
   - Nozick: No – charity must be voluntary.

3. Should natural talents justify unequal rewards?
   - Rawls: No – arbitrary.
   - Nozick: Yes – as long as acquired/used justly.



---
---

# 📘 Ethics Lecture 11: Adam Smith, Milton Friedman & Business Ethics

### 🧠 Core Themes
- Compatibility of ethics with business
- Shareholder theory vs stakeholder theory
- Fiduciary responsibilities in the digital age
- Free market ethics (Smith, Friedman) vs social responsibility

---

## 📊 I. Capitalism, Ethics, and the Free Market

### Adam Smith (1723–1790)
- **Father of capitalism**; friend of David Hume
- **Invisible hand**: Pursuing self-interest can unintentionally promote the public good
- **Division of labour**: Self-interest leads to efficiency → specialization → great wealth
- Not ruthless: A moral philosopher who recognized limits to self-interest
- Argued for **free trade**, with rare exceptions (e.g. national defense, retaliatory tariffs)

#### Notable Quote
> “It is not from the benevolence of the butcher, the brewer, or the baker that we expect our dinner, but from their regard to their own interest.”

---

## 💼 II. Milton Friedman (1912–2006)

### Shareholder Theory
- The **sole responsibility** of business: **maximize profits**
- Ethical obligation of CEOs is to **owners/shareholders**, not society
- Acting socially responsible = spending someone else's money

#### Two Key Arguments:
1. **Libertarian** view: No coercion; taxation = theft
2. **Market distortion**: Social goals distort the free market (Friedman calls this "unrigorous" or “socialism in disguise”)

#### Caveat
- Business must play “within the rules”: No deception or fraud
- Business ≠ individual → Only individuals have social responsibility (in personal roles, not as agents)

---

## 🔄 III. Stakeholder vs Shareholder Theory

| Shareholder Theory (Friedman) | Stakeholder Theory |
|------------------------------|---------------------|
| Duty to shareholders only     | Duty to all affected parties (users, community, employees) |
| Profit maximization is priority | Balance interests, even if profits are reduced |
| Social goals = private matters | Social impact = ethical and strategic concern |

---

## 🔐 IV. Data Fiduciaries and Digital Ethics

### Canadian Bar Association (CBA) Position
- **Data is the new oil**
- Many companies collect, use, and sell user data with no **fiduciary duty**
- Fiduciary duty = legal and ethical trust obligation
- CBA advocates for **“data fiduciaries”**:
  - Must act in the best interest of users
  - Must avoid harm, discrimination, and exploitation of data

---

## 🧩 V. Business Ethics Dilemmas (Discussion Contexts)

| Scenario | Ethical Conflict |
|---------|------------------|
| **App with data vulnerability** | Delay = ethical (protect users) vs Launch = profit (Friedman) |
| **Biased AI hiring tool** | Bias harms equity; fixing = cost |
| **Mining optimization software** | Greater profit vs environmental damage |

---

## 🧠 Critical Reflection

### Arguments **For** Friedman:
- CEOs are agents, not social reformers
- Market incentives regulate behavior better than imposed values
- Social responsibility without clear metrics leads to inefficiency or coercion

### Arguments **Against** Friedman:
- Ethical obligations exist beyond the law (e.g. data trust)
- Market failures and loopholes show need for responsibility beyond profit
- Stakeholder theory reflects real-world complexity

---
---

# 📘 Lecture 12: Stakeholder Theory & Virtue Ethics in Business  
**Theme**: Ethics **can** and **should** guide business practices—not just policy, but daily character and decisions.

---

### 🧠 I. Background Context

- **Last week (Friedman)**: Maximize profit, ignore “social responsibility”  
- **This week (Solomon, Stakeholder theory)**: Business can and should be ethical—ethics is essential, not optional

---

## 📊 II. Stakeholder Theory

### 🌐 Main Idea
- Directors have **responsibilities to all stakeholders**, not just shareholders.
- Stakeholders include: employees, customers, suppliers, creditors, communities, future generations

### 💡 Origin
- Emerged during the **1930s** – against selfish corporate models
- Revived by **R. Edward Freeman (1980s)**

### ✅ Ethical Responsibilities > Legal Obligations
- Ethics includes implicit **social contracts** beyond legal minimums  
- **Samsung refund case**: refund wasn’t legally required but was ethically correct and beneficial in the long term

### 🔍 Challenges to Friedman:
1. **Shareholders don’t think alike** (Lynn Stout)
2. **Morality isn’t zero-sum** – ethics can increase long-term profits
3. **Motive matters** – don’t dismiss ethics just because it also makes money

---

## 👤 III. Robert Solomon: Aristotelian Virtue Ethics in Business

### 🎯 Focus
- **Not** policy-making, grand theory, or laws
- **Instead**: Focus on the **character and judgment of individuals** within businesses
- Ethics isn't external to business—it’s **within roles, habits, and values**

---

### 🔶 Solomon’s Six Dimensions of Virtue Ethics

| Virtue Dimension | Explanation |
|------------------|-------------|
| **Community** | Business is a social, cooperative activity. Self-interest overlaps with group interest. |
| **Excellence** | Strive to be the best version of yourself (not just “don’t do harm”) |
| **Role Identity** | Your job brings **specific duties** (e.g., loyalty, diligence, fairness) |
| **Integrity** | Wholeness of character—balance different loyalties, resist temptation |
| **Judgment (Phronesis)** | Practical wisdom; no formula can tell you what’s right in every case |
| **Holism** | Integrate personal and professional life—don’t “split” them |

---

### 🔄 Contrast with Other Ethical Theories

| Theory | Solomon’s Critique |
|--------|---------------------|
| **Kant** | Overly rigid, ignores real-world complexity & personal growth |
| **Utilitarianism** | Impersonal, mechanistic; neglects character and virtues |
| **Friedman** | Misunderstands self-interest; assumes ethics ≠ business success |

---

## 🔎 IV. Virtue in Practice

### ✔ Virtues in Business
- Loyalty, charm, civility, diligence, resilience, hospitality, humor…
- Even **toughness** can be a virtue if exercised with integrity
- The best way to **appear ethical**: **be ethical**

### 💡 Case Example: Nuclear Waste Repository
- Stakeholders include nearby communities, environmental bodies, employees
- Stakeholder view: Good ethics = good business in the long run

---

## 🤔 V. Key Discussion Points

### 📍 Question 1:  
**Can you be tough in business and still ethical?**  
→ Yes. Firing good employees to save the company may be **tough but virtuous**, if done responsibly.

### 📍 Question 2:  
**Can business toughness ever force unethical action?**  
→ Possible counterexamples exist: situations where profit-maximizing pressure **overrides moral judgment**, e.g. exploitation, data misuse.

---

## 💬 Key Quotes

- “Business is not just poker.” – Robert Solomon  
- “There’s no antagonism between self-interest and public good.” (p. 322)  
- “Good employees are good people.” (p. 329)  
- “The best way to appear ethical is to **be** ethical.”

---

## 📝 Summary: Friedman vs Stakeholder Theory

| Concept | Friedman | Stakeholder Theory / Solomon |
|--------|-----------|------------------------------|
| Primary Goal | Maximize profit | Balance all stakeholder interests |
| Ethics | Private; not part of business | Core to business identity |
| Responsibility | Only to shareholders | To all who are affected |
| Motivation | Profit-first | Virtue and integrity |
| View on Ethics | External limitation | Internal character development |

